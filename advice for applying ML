1
-split the dataset as training set 60% cross validation set 20% and test set 20%

2
-training set
Ã–ÄŸrencinin ders Ã§alÄ±ÅŸtÄ±ÄŸÄ± kitap gibi dÃ¼ÅŸÃ¼n.
Model parametreleri (ð‘¤,b) bu verilerden ayarlanÄ±r.

-cross-validation set
Bu veriler Ã¶ÄŸrenme iÃ§in kullanÄ±lmaz, sadece model seÃ§mek iÃ§in kullanÄ±lÄ±r.
Ã–ÄŸrencinin ders Ã§alÄ±ÅŸtÄ±ktan sonra yaptÄ±ÄŸÄ± deneme sÄ±navÄ± gibi dÃ¼ÅŸÃ¼n.
AsÄ±l kararlarÄ± burada veriyoruz. Yani â€œbu model fazla ezberlemiÅŸ (overfit)â€ mi,
 â€œbu model Ã§ok basit (underfit)â€ mi diye buradan anlÄ±yoruz.

 -test set
 Ã–ÄŸrencinin gerÃ§ek final sÄ±navÄ± gibi dÃ¼ÅŸÃ¼n.
Modeli eÄŸittik, validation ile en iyi modeli seÃ§tik â†’ en sonunda test setinde final performansÄ± raporlarÄ±z
*Tek seferlik kullanÄ±lÄ±r â†’ sÃ¼rekli bakarsak test seti de â€œezberlenmiÅŸâ€ olur.

EÄŸitim â†’ Ã¶ÄŸrenmek iÃ§in.
Validation â†’ modeli seÃ§mek iÃ§in.
Test â†’ baÅŸarÄ±yÄ± Ã¶lÃ§mek iÃ§in.

3
high bias (underfit) -> J train is high, Jcv is high     J train in high olmasÄ±, Jcv nin de high olduÄŸunu anlamamÄ±zÄ± saÄŸlaar
just right  -> J train is low, Jcv is low
high variance (overfit) -> J train is low, Jcv is high

Jtrain â†’ EÄŸitim verisi Ã¼zerinde cost. Model ders kitabÄ±ndaki sorularÄ± Ã§Ã¶zerken yaptÄ±ÄŸÄ± hata.
Jcv â†’ Validation verisi (cross-validation set) Ã¼zerinde cost. Modelin deneme sÄ±navÄ±nda (validation set) yaptÄ±ÄŸÄ± hata.
Jtest â†’ En son test seti Ã¼zerinde cost. Modelin gerÃ§ek sÄ±navda (test set) yaptÄ±ÄŸÄ± hata.

regularization parameter lambda artarsa penalizing Ã§ok olur, underfit(high bias) olur Jtrain ve Jcv fazla,
lambda Ã§ok az olursa overfit(high variance) durumu kalÄ±r Jtrain az Jcv fazla

4
where the data is sometimes noisy, it is useful to establish a baseline level of performance
(like human level performance).(like speech recognition example)
Ex: for the first example 10.8% - 10.6% = 0.2% then we say the model is fitting well to the training data

baseline performance        : 10.6%             10.6%               10.6%
training error (Jtrain)     : 10.8%             15.0%               15.0%
cross validation error (Jcv): 14.8%             15.5%               19.7%
                           high variance       high bias    high bias & high variance

bias: Modelin ortalama tahmininin gerÃ§ek fonksiyondan ne kadar uzak olduÄŸunu Ã¶lÃ§er
variance: Modelin tahminlerinin farklÄ± eÄŸitim setleri arasÄ±nda ne kadar deÄŸiÅŸtiÄŸini Ã¶lÃ§er

5
training set size'Ä±nÄ± artÄ±rdÄ±kÃ§a modelin ezberlemesi zorlaÅŸÄ±r, genelleme yeteneÄŸi artar. o yÃ¼zden training set size
arttÄ±kÃ§a Jcv azalÄ±r Ã§Ã¼nkÃ¼ overfit (high variance) ihtimali gitgide azalÄ±r

training set size arttÄ±kÃ§a Jtrain artar Ã§Ã¼nkÃ¼ modelin tÃ¼m noktalardan geÃ§iyor olmasÄ± giderek zorlaÅŸÄ±r. Ã¶r: 2 tane olsa
dÃ¼z Ã§izgi ile Jtrain yani training error 0 olur ama 10 tane olsa her birine tam tamÄ±na uyamayacaÄŸÄ± iÃ§in genelleme
yapmak zorunda o yÃ¼zden Jtrain artmaya baÅŸlar

high bias varsa baseline level performance'a ulaÅŸmasÄ± iÃ§in daha Ã§ok data eklemek iÅŸe yaramaz. Jtrain ve Jcv flatten
olur ve hala baseline level performance ile arasÄ±nda bÃ¼yÃ¼k bir boÅŸluk vardÄ±r ve yeni data eklemek bu mesafeyi kÄ±saltamaz
Ã§Ã¼nkÃ¼ baseline level, flatten olduÄŸu yerin aÅŸaÄŸÄ±sÄ±ndadÄ±r.
high variance varsa daha Ã§ok data eklemek iÅŸe yarar. Ã§Ã¼nkÃ¼ baseline level, Jtrain ile Jcv nin arasÄ±ndadÄ±r ve data
ekledikÃ§e bu noktaya yaklaÅŸarak flatten olur.

Ã–nemli: Bu validation fold aÄŸÄ±rlÄ±klarÄ± deÄŸiÅŸtirmez, yani model burada doÄŸrudan Ã¶ÄŸrenmez. Ama:
EÄŸer hyperparameter tuning yapÄ±yorsan, CV sonuÃ§larÄ±na gÃ¶re learning rate, layer sayÄ±sÄ± gibi ayarlar deÄŸiÅŸtirirsin.
Bu ayarlamalar dolaylÄ± olarak modelin Ã¶ÄŸrenme sÃ¼recini etkiler.
CV validation fold â†’ aÄŸÄ±rlÄ±klarÄ± gÃ¼ncellemez ama model seÃ§im/ayarlama sÃ¼recinde kullanÄ±lÄ±r. ayar yapma kÄ±smÄ±. e gÃ¶re
Test set â†’ hiÃ§bir ayarlama veya seÃ§im iÃ§in kullanÄ±lmaz, sadece performans Ã¶lÃ§er
Test sete gÃ¶re ayarlama yaparsak ne olur?
EÄŸer test loss/accuracyâ€™yi gÃ¶rÃ¼p manuel olarak hyperparametreleri deÄŸiÅŸtirirsen â†’ model test setten Ã¶ÄŸrenmiÅŸ gibi olur.
Bu yÃ¼zden test set kesinlikle eÄŸitim veya tuning iÃ§in kullanÄ±lmaz.
backpropagation

train:                  forward propagation & back propagation(updates the weights of the model)
cross validation:       forward propagation
test:                   forward propagation

6
debugging a learning algorithm:
- get more training examples          fixes high variance
- try smaller sets of features        fixes high variance
- try getting additional features     fixes high bias
- try adding polynomial features      fixes high bias
- try decreasing lambda               fixes high bias
- try increasing lambda               fixes high variance

to fix high bias, make the model more powerful or give it more flexibility
to fix high variance, get more training data or simplify the model

7
large neural networks are low bias machines

does it do well on the training set? if no, use bigger neural network
if yes, does it do well on the cross validation set? if no, add more data
if yes, Done!

a large neural network will usually do as well or better than
a smaller one so long as regularization is chosen appropriately

eÄŸitim seti Ã§ok kÃ¼Ã§Ã¼k deÄŸilse, neural networkler, especially large neural networks dÃ¼ÅŸÃ¼k biasâ€™lÄ±dÄ±r

if there is high bias, compare the training error to the baseline level of performance
if there is high variance, compare the cross validation error to the training error

8
Iterative loop of ml development
1-choose architecture(model, data, hyperparameters, etc.)
2-train model
3-diagnostics(bias, variance and error analysis)

9
Error analysis
manually examine 100 examples and categorise them based on common traits
model, kasÄ±tlÄ± yazÄ±m hatalarÄ±nÄ± Ã§ok iyi Ã§Ã¶zebiliyordur ama bu, spam olan emaillerin sadece %3 Ã¼nÃ¼ kapsÄ±yordur.
o yÃ¼zden manuel error analysis yaparÄ±z. bias, variance den sonra 2. olarak

pharma                                  21    more data, features
deliberate misspellings                 3
unusual email routing                   7
steal passwords                         18    more data, features
spam message in embedded image          5
-this may give inspiration what might be useful to try next

8
Adding data
add more data of the types where error analysis has indicated it might help
data augmentation: modifying an existing training example to create a new training example ex: A yÄ± yan Ã§evir,
blurla, bÃ¼yÃ¼t, kÃ¼Ã§Ã¼lt, simetriÄŸini al...
A ya Ä±zgaralÄ± Ã¼zerindeki gibi distortion(Ã§arpÄ±tma) yap.
ses iÃ§in: noisy background (crowd, car), audio on bad cellphone connection...
not: distortion introduced should be representation of the type of noise/distortions in the test set
not: usually does not help to add purely random/meaningless noise to your data. ex: EÄŸer doÄŸada karÅŸÄ±laÅŸabileceÄŸin
bir bozulmayÄ± (bulanÄ±klÄ±k, Ä±ÅŸÄ±k farkÄ±, sensÃ¶r gÃ¼rÃ¼ltÃ¼sÃ¼) simÃ¼le ediyorsak faydalÄ±
EÄŸer sadece rastgele buzulmalar ekliyorsan anlamsÄ±z, zararlÄ±
data synthesis: using artificial data inputs to create a new training example ex: farklÄ± fontlarda rastgele harfler
yaz(with different colors, different contrast etc.) ve screenshot al ve bunu synthetic data olarak kullan

AI = Code + Data
conventional model-centric approach: focus on code
data centric approach: focus on data

9
Transfer learning
belirli bir task iÃ§in elimizde yeteri kadar training data olmadÄ±ÄŸÄ±nda baÅŸka verilerle bir model eÄŸitip, o modelin
parametrelerini, istediÄŸimiz modele uygulayarak modeli daha zeki hale getirip az training data ile daha verimli bir
model kurmayÄ± amaÃ§larÄ±z. output layer units leri istediÄŸimiz outputa uygun ayarlarÄ±z.
option1: only train output layers parameters
-Ã¶nceden eÄŸitilmiÅŸ parametreleri dondurursun. Ã§ok az data olsa bile overfitting yapmaz,
 Ã§Ã¼nkÃ¼ milyonlarca parametreyi oynatmÄ±yoz. ama uyum sÄ±nÄ±rlÄ± olabilir
option2: train all parameters
-baÅŸlangÄ±Ã§ noktasÄ± olarak yine Ã¶nceden eÄŸitilmiÅŸ parametreleri alÄ±rsÄ±n,
ama bu sefer hepsini tekrar eÄŸitmeye izin verirsin
model, bizim taskÄ±mÄ±za daha fazla Ã¶zelleÅŸebilir, az veri varsa overfitting riski yÃ¼ksek (her parametreyi ayarlÄ±yoz)
her parametreyi ayarlÄ±yoz ama zaten iyi bir noktadan baÅŸlayarak yapÄ±yoruz bunu, bizim verimize gÃ¶re ince ayar yapÄ±lÄ±yor
training set Ã§ok azsa option1, biraz daha fazlaysa option2 daha iyi olur.
(ama her ikisi de yetersizmiÅŸ ki transfer learning yapÄ±yoz)
step1 -> supervised pretraining   step2 -> fine tuning
100 lerce, 1000 lerce veri varsa 1 milyon ile supervised pretraining yap, sonra o 100 lerce 1000 lerce datayla
fine tuning yap.
ama bunu zaten yapÄ±p internete yÃ¼kleyenler var. onlarÄ±n pretrained modellerini al, output layeri kendi istediÄŸine
gÃ¶re ayarla, option1 ya da option2 ile o zaten ileri gÃ¶tÃ¼rÃ¼lmÃ¼ÅŸ olan modeli kendi datanla eÄŸit.
pretrained modeli hazÄ±r al, sonrasÄ±nda kendin evinde gÃ¼zel gÃ¼zel fine tuning yap

pretirained model ile same input type kullanmamÄ±z gerek. mesela pretrained imagede kenar, kÃ¶ÅŸe, eÄŸim, basic shapes
falan Ã¶ÄŸreniyo ve bizim handwritten diÄŸit de de kenar, kÃ¶ÅŸe, shape var.

bu yÃ¶ntem her zaman iÅŸe yaramaz ama Ã§ok yardÄ±mcÄ± olabilir

10
Full cycle of a machine learning project
scope project      ->      collect data      ->      train model     ->      deploy in production
(define project)  (define and collect data)  (training, error analysis   (deploy, monitor and maintain system)
                                              & iterative improvement)
train model'den collect data'ya, deploy'dan train model'e ya da deploy'dan collect data'ya dÃ¶nmen gerekebilir

deployment:
inference server (inside) ML model ----->    <----- Mobile app
             inference(text transcript)(y^)   API call (audio clip)(x)
-ensure reliable and efficient products
-scaling
-logging
-system monitoring
-model updates